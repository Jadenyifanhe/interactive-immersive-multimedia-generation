# Interactive Immersive Multimedia Generation

## Overview

This is the project repository for CMU 10-615 Art and Machine Learning's final project. Given a spoken speech as input, we generate a film that consits of music, lyrics, and images.

The text to image generation part is based on [FuseDream](https://github.com/gnobitab/FuseDream).

## Our Team

- Zhouyao Xie: School of Computer Science, Language Technology Institute, Master of Computational Data Science
- Nikhil Yadala: School of Computer Science, Language Technology Institute, Master of Computational Data Science
- Yifan He: College of Fine Arts, School of Music, Music and Technology
- Guannan Tang: College of Engineering, Materials Science Department

## Report & Presentation

Our report is included in this repository. You can also check out our report via [this link](https://docs.google.com/document/d/1n7jtXed6hKWhCfQGKV0GhT0UWBGgBF_y/edit?usp=sharing&ouid=100645612073317945557&rtpof=true&sd=true).

Our presentation slide can be found [here](https://docs.google.com/presentation/d/119QP-hJ5BajnJeNcwqrSVAARHUDr09Vg1w8m0VyIjGA/edit?usp=sharing).
